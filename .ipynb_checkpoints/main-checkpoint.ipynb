{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd487d7-4232-4494-a6e1-96d61dd8a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-contrib-python\n",
    "#!pip install opencv-python mediapipe pyttsx3 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea71d26-619a-4a75-ae99-f60f679881c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n",
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20a6baf-ce99-498c-8eee-7a98b24c645e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe' has no attribute 'solutions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 548\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# RUN APPLICATION\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 548\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mExerciseGradingSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[1;32mIn[3], line 436\u001b[0m, in \u001b[0;36mExerciseGradingSystem.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpose_analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mPoseAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mform_feedback \u001b[38;5;241m=\u001b[39m FormFeedback()\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoice_coach \u001b[38;5;241m=\u001b[39m VoiceCoach(enabled\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mVOICE_ENABLED)\n",
      "Cell \u001b[1;32mIn[3], line 100\u001b[0m, in \u001b[0;36mPoseAnalyzer.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Initialize MediaPipe Pose\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_pose \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolutions\u001b[49m\u001b[38;5;241m.\u001b[39mpose\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_pose\u001b[38;5;241m.\u001b[39mPose(\n\u001b[0;32m    102\u001b[0m         min_detection_confidence\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mPOSE_CONFIDENCE,\n\u001b[0;32m    103\u001b[0m         min_tracking_confidence\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mPOSE_CONFIDENCE,\n\u001b[0;32m    104\u001b[0m         model_complexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 0=Lite, 1=Full, 2=Heavy (1 is good for CPU)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_draw \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'solutions'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AI Exercise Form Grading System\n",
    "Real-time squat form analysis with quality feedback\n",
    "\n",
    "Requirements:\n",
    "pip install opencv-python mediapipe pyttsx3 numpy\n",
    "\"\"\"\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "import threading\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"System configuration constants\"\"\"\n",
    "    # Angle thresholds for squat phases (degrees)\n",
    "    STANDING_KNEE_ANGLE = 160\n",
    "    SQUAT_DEPTH_KNEE_ANGLE = 90\n",
    "    GOOD_SQUAT_MIN = 70\n",
    "    GOOD_SQUAT_MAX = 110\n",
    "    \n",
    "    # Hip angle thresholds\n",
    "    HIP_ANGLE_MIN = 70\n",
    "    HIP_ANGLE_MAX = 120\n",
    "    \n",
    "    # Back angle thresholds (torso to vertical)\n",
    "    BACK_ANGLE_MAX = 45  # Maximum forward lean\n",
    "    \n",
    "    # Knee tracking threshold (knee shouldn't go too far forward)\n",
    "    KNEE_FORWARD_RATIO = 0.1  # Relative to foot position\n",
    "    \n",
    "    # Confidence and smoothing\n",
    "    POSE_CONFIDENCE = 0.5\n",
    "    ANGLE_SMOOTH_FRAMES = 5\n",
    "    \n",
    "    # Voice feedback\n",
    "    VOICE_ENABLED = True\n",
    "    VOICE_COOLDOWN = 3.0  # Seconds between voice feedbacks\n",
    "\n",
    "# ============================================================================\n",
    "# VOICE FEEDBACK SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "class VoiceCoach:\n",
    "    \"\"\"Handles text-to-speech feedback\"\"\"\n",
    "    \n",
    "    def __init__(self, enabled=True):\n",
    "        self.enabled = enabled\n",
    "        self.last_feedback_time = 0\n",
    "        self.cooldown = Config.VOICE_COOLDOWN\n",
    "        \n",
    "        if self.enabled:\n",
    "            try:\n",
    "                self.engine = pyttsx3.init()\n",
    "                self.engine.setProperty('rate', 150)  # Speed\n",
    "                self.engine.setProperty('volume', 0.9)  # Volume\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è Voice feedback unavailable. Continuing without TTS.\")\n",
    "                self.enabled = False\n",
    "    \n",
    "    def speak(self, text, priority=False):\n",
    "        \"\"\"Speak feedback with cooldown to avoid spam\"\"\"\n",
    "        if not self.enabled:\n",
    "            return\n",
    "        \n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Check cooldown unless high priority\n",
    "        if not priority and (current_time - self.last_feedback_time) < self.cooldown:\n",
    "            return\n",
    "        \n",
    "        self.last_feedback_time = current_time\n",
    "        \n",
    "        # Run in separate thread to not block video\n",
    "        def _speak():\n",
    "            try:\n",
    "                self.engine.say(text)\n",
    "                self.engine.runAndWait()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        thread = threading.Thread(target=_speak, daemon=True)\n",
    "        thread.start()\n",
    "\n",
    "# ============================================================================\n",
    "# POSE DETECTION AND ANGLE CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "class PoseAnalyzer:\n",
    "    \"\"\"Handles pose detection and angle calculations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe Pose\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            min_detection_confidence=Config.POSE_CONFIDENCE,\n",
    "            min_tracking_confidence=Config.POSE_CONFIDENCE,\n",
    "            model_complexity=1  # 0=Lite, 1=Full, 2=Heavy (1 is good for CPU)\n",
    "        )\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        \n",
    "        # Angle smoothing\n",
    "        self.angle_history = {\n",
    "            'left_knee': deque(maxlen=Config.ANGLE_SMOOTH_FRAMES),\n",
    "            'right_knee': deque(maxlen=Config.ANGLE_SMOOTH_FRAMES),\n",
    "            'left_hip': deque(maxlen=Config.ANGLE_SMOOTH_FRAMES),\n",
    "            'right_hip': deque(maxlen=Config.ANGLE_SMOOTH_FRAMES),\n",
    "            'back': deque(maxlen=Config.ANGLE_SMOOTH_FRAMES)\n",
    "        }\n",
    "    \n",
    "    def calculate_angle(self, point1, point2, point3):\n",
    "        \"\"\"\n",
    "        Calculate angle between three points\n",
    "        \n",
    "        Args:\n",
    "            point1, point2, point3: Tuples of (x, y) coordinates\n",
    "            point2 is the vertex of the angle\n",
    "        \n",
    "        Returns:\n",
    "            Angle in degrees\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        p1 = np.array(point1)\n",
    "        p2 = np.array(point2)\n",
    "        p3 = np.array(point3)\n",
    "        \n",
    "        # Calculate vectors\n",
    "        vector1 = p1 - p2\n",
    "        vector2 = p3 - p2\n",
    "        \n",
    "        # Calculate angle using arctan2 for better accuracy\n",
    "        angle = np.degrees(\n",
    "            np.arctan2(vector2[1], vector2[0]) - \n",
    "            np.arctan2(vector1[1], vector1[0])\n",
    "        )\n",
    "        \n",
    "        # Normalize to 0-180 range\n",
    "        angle = abs(angle)\n",
    "        if angle > 180:\n",
    "            angle = 360 - angle\n",
    "            \n",
    "        return angle\n",
    "    \n",
    "    def get_landmarks(self, frame):\n",
    "        \"\"\"\n",
    "        Process frame and extract pose landmarks\n",
    "        \n",
    "        Returns:\n",
    "            landmarks dict or None if pose not detected\n",
    "        \"\"\"\n",
    "        # Convert to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.pose.process(rgb_frame)\n",
    "        \n",
    "        if not results.pose_landmarks:\n",
    "            return None\n",
    "        \n",
    "        # Extract key landmarks\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        def get_coords(landmark_id):\n",
    "            lm = landmarks[landmark_id]\n",
    "            return (int(lm.x * w), int(lm.y * h))\n",
    "        \n",
    "        return {\n",
    "            'left_hip': get_coords(self.mp_pose.PoseLandmark.LEFT_HIP),\n",
    "            'right_hip': get_coords(self.mp_pose.PoseLandmark.RIGHT_HIP),\n",
    "            'left_knee': get_coords(self.mp_pose.PoseLandmark.LEFT_KNEE),\n",
    "            'right_knee': get_coords(self.mp_pose.PoseLandmark.RIGHT_KNEE),\n",
    "            'left_ankle': get_coords(self.mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "            'right_ankle': get_coords(self.mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "            'left_shoulder': get_coords(self.mp_pose.PoseLandmark.LEFT_SHOULDER),\n",
    "            'right_shoulder': get_coords(self.mp_pose.PoseLandmark.RIGHT_SHOULDER),\n",
    "            'nose': get_coords(self.mp_pose.PoseLandmark.NOSE),\n",
    "            'raw': results.pose_landmarks\n",
    "        }\n",
    "    \n",
    "    def calculate_body_angles(self, landmarks):\n",
    "        \"\"\"Calculate all relevant angles for squat analysis\"\"\"\n",
    "        \n",
    "        # Left knee angle (hip-knee-ankle)\n",
    "        left_knee_angle = self.calculate_angle(\n",
    "            landmarks['left_hip'],\n",
    "            landmarks['left_knee'],\n",
    "            landmarks['left_ankle']\n",
    "        )\n",
    "        \n",
    "        # Right knee angle\n",
    "        right_knee_angle = self.calculate_angle(\n",
    "            landmarks['right_hip'],\n",
    "            landmarks['right_knee'],\n",
    "            landmarks['right_ankle']\n",
    "        )\n",
    "        \n",
    "        # Left hip angle (shoulder-hip-knee)\n",
    "        left_hip_angle = self.calculate_angle(\n",
    "            landmarks['left_shoulder'],\n",
    "            landmarks['left_hip'],\n",
    "            landmarks['left_knee']\n",
    "        )\n",
    "        \n",
    "        # Right hip angle\n",
    "        right_hip_angle = self.calculate_angle(\n",
    "            landmarks['right_shoulder'],\n",
    "            landmarks['right_hip'],\n",
    "            landmarks['right_knee']\n",
    "        )\n",
    "        \n",
    "        # Back angle (vertical alignment)\n",
    "        # Calculate torso line angle from vertical\n",
    "        mid_shoulder = (\n",
    "            (landmarks['left_shoulder'][0] + landmarks['right_shoulder'][0]) // 2,\n",
    "            (landmarks['left_shoulder'][1] + landmarks['right_shoulder'][1]) // 2\n",
    "        )\n",
    "        mid_hip = (\n",
    "            (landmarks['left_hip'][0] + landmarks['right_hip'][0]) // 2,\n",
    "            (landmarks['left_hip'][1] + landmarks['right_hip'][1]) // 2\n",
    "        )\n",
    "        \n",
    "        # Create vertical reference point\n",
    "        vertical_point = (mid_hip[0], mid_hip[1] - 100)\n",
    "        back_angle = self.calculate_angle(vertical_point, mid_hip, mid_shoulder)\n",
    "        \n",
    "        # Smooth angles\n",
    "        self.angle_history['left_knee'].append(left_knee_angle)\n",
    "        self.angle_history['right_knee'].append(right_knee_angle)\n",
    "        self.angle_history['left_hip'].append(left_hip_angle)\n",
    "        self.angle_history['right_hip'].append(right_hip_angle)\n",
    "        self.angle_history['back'].append(back_angle)\n",
    "        \n",
    "        return {\n",
    "            'left_knee': np.mean(self.angle_history['left_knee']),\n",
    "            'right_knee': np.mean(self.angle_history['right_knee']),\n",
    "            'left_hip': np.mean(self.angle_history['left_hip']),\n",
    "            'right_hip': np.mean(self.angle_history['right_hip']),\n",
    "            'back': np.mean(self.angle_history['back']),\n",
    "            'avg_knee': (np.mean(self.angle_history['left_knee']) + \n",
    "                        np.mean(self.angle_history['right_knee'])) / 2\n",
    "        }\n",
    "    \n",
    "    def check_knee_tracking(self, landmarks):\n",
    "        \"\"\"Check if knees are tracking properly over feet\"\"\"\n",
    "        # Check if knees go too far forward past toes\n",
    "        left_knee_x = landmarks['left_knee'][0]\n",
    "        left_ankle_x = landmarks['left_ankle'][0]\n",
    "        \n",
    "        right_knee_x = landmarks['right_knee'][0]\n",
    "        right_ankle_x = landmarks['right_ankle'][0]\n",
    "        \n",
    "        # Calculate forward tracking (negative means knee is behind ankle - good)\n",
    "        left_forward = (left_knee_x - left_ankle_x) / 100  # Normalize\n",
    "        right_forward = (right_knee_x - right_ankle_x) / 100\n",
    "        \n",
    "        return {\n",
    "            'left': left_forward,\n",
    "            'right': right_forward,\n",
    "            'excessive': left_forward > Config.KNEE_FORWARD_RATIO or \n",
    "                        right_forward > Config.KNEE_FORWARD_RATIO\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# FORM FEEDBACK SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "class FormFeedback:\n",
    "    \"\"\"Analyzes form and provides quality feedback\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rep_count = 0\n",
    "        self.in_squat = False\n",
    "        self.feedback_messages = []\n",
    "        self.form_score = 100\n",
    "        \n",
    "    def analyze_squat_form(self, angles, knee_tracking):\n",
    "        \"\"\"\n",
    "        Analyze squat form and generate feedback\n",
    "        \n",
    "        Returns:\n",
    "            dict with feedback, score, and issues\n",
    "        \"\"\"\n",
    "        feedback = []\n",
    "        issues = []\n",
    "        score = 100\n",
    "        \n",
    "        knee_angle = angles['avg_knee']\n",
    "        hip_angle = (angles['left_hip'] + angles['right_hip']) / 2\n",
    "        back_angle = angles['back']\n",
    "        \n",
    "        # === DEPTH CHECK ===\n",
    "        if knee_angle > Config.GOOD_SQUAT_MAX:\n",
    "            feedback.append(\"‚¨áÔ∏è Go deeper\")\n",
    "            issues.append('shallow')\n",
    "            score -= 20\n",
    "        elif knee_angle < Config.GOOD_SQUAT_MIN:\n",
    "            feedback.append(\"‚¨ÜÔ∏è Not too deep\")\n",
    "            issues.append('too_deep')\n",
    "            score -= 10\n",
    "        \n",
    "        # === BACK POSITION CHECK ===\n",
    "        if back_angle > Config.BACK_ANGLE_MAX:\n",
    "            feedback.append(\"üî∫ Keep chest up - back too bent\")\n",
    "            issues.append('back_bent')\n",
    "            score -= 25\n",
    "        \n",
    "        # === HIP ANGLE CHECK ===\n",
    "        if hip_angle < Config.HIP_ANGLE_MIN:\n",
    "            feedback.append(\"üîÑ Open hips more\")\n",
    "            issues.append('hips_tight')\n",
    "            score -= 15\n",
    "        elif hip_angle > Config.HIP_ANGLE_MAX:\n",
    "            feedback.append(\"üîÑ Engage hips more\")\n",
    "            issues.append('hips_loose')\n",
    "            score -= 10\n",
    "        \n",
    "        # === KNEE TRACKING CHECK ===\n",
    "        if knee_tracking['excessive']:\n",
    "            feedback.append(\"‚ö†Ô∏è Knees too far forward\")\n",
    "            issues.append('knee_forward')\n",
    "            score -= 20\n",
    "        \n",
    "        # === GOOD FORM ===\n",
    "        if not feedback:\n",
    "            feedback.append(\"‚úÖ Perfect form!\")\n",
    "            \n",
    "        return {\n",
    "            'feedback': feedback,\n",
    "            'issues': issues,\n",
    "            'score': max(0, score),\n",
    "            'is_good_form': score >= 80\n",
    "        }\n",
    "    \n",
    "    def update_rep_count(self, angles):\n",
    "        \"\"\"Track squat reps with state machine\"\"\"\n",
    "        knee_angle = angles['avg_knee']\n",
    "        \n",
    "        # State: Standing -> Squatting\n",
    "        if not self.in_squat and knee_angle < Config.STANDING_KNEE_ANGLE:\n",
    "            self.in_squat = True\n",
    "        \n",
    "        # State: Squatting -> Standing (rep completed)\n",
    "        elif self.in_squat and knee_angle > Config.STANDING_KNEE_ANGLE:\n",
    "            self.in_squat = False\n",
    "            self.rep_count += 1\n",
    "            return True  # Rep completed\n",
    "        \n",
    "        return False  # No rep completed\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Handles on-screen display and overlays\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_angle(frame, point1, point2, point3, angle, color=(255, 255, 255)):\n",
    "        \"\"\"Draw angle arc and value\"\"\"\n",
    "        # Draw lines\n",
    "        cv2.line(frame, point1, point2, color, 2)\n",
    "        cv2.line(frame, point2, point3, color, 2)\n",
    "        \n",
    "        # Draw circles at joints\n",
    "        cv2.circle(frame, point2, 8, color, -1)\n",
    "        cv2.circle(frame, point1, 5, color, -1)\n",
    "        cv2.circle(frame, point3, 5, color, -1)\n",
    "        \n",
    "        # Draw angle text\n",
    "        cv2.putText(frame, f\"{int(angle)}¬∞\", \n",
    "                   (point2[0] + 15, point2[1] - 15),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def draw_feedback_panel(frame, feedback_data, rep_count):\n",
    "        \"\"\"Draw feedback panel on frame\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Semi-transparent overlay\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (400, 250), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "        \n",
    "        # Title\n",
    "        cv2.putText(frame, \"SQUAT ANALYZER\", (20, 40),\n",
    "                   cv2.FONT_HERSHEY_BOLD, 0.8, (0, 255, 255), 2)\n",
    "        \n",
    "        # Rep count\n",
    "        cv2.putText(frame, f\"Reps: {rep_count}\", (20, 80),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Form score\n",
    "        score = feedback_data['score']\n",
    "        score_color = (0, 255, 0) if score >= 80 else (0, 165, 255) if score >= 60 else (0, 0, 255)\n",
    "        cv2.putText(frame, f\"Form Score: {score}/100\", (20, 115),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, score_color, 2)\n",
    "        \n",
    "        # Feedback messages\n",
    "        y_offset = 150\n",
    "        for msg in feedback_data['feedback']:\n",
    "            cv2.putText(frame, msg, (20, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            y_offset += 30\n",
    "    \n",
    "    @staticmethod\n",
    "    def highlight_problem_joints(frame, landmarks, issues):\n",
    "        \"\"\"Highlight joints with form issues in red\"\"\"\n",
    "        if 'back_bent' in issues:\n",
    "            # Highlight spine\n",
    "            cv2.circle(frame, landmarks['left_shoulder'], 12, (0, 0, 255), 3)\n",
    "            cv2.circle(frame, landmarks['right_shoulder'], 12, (0, 0, 255), 3)\n",
    "        \n",
    "        if 'knee_forward' in issues or 'shallow' in issues or 'too_deep' in issues:\n",
    "            # Highlight knees\n",
    "            cv2.circle(frame, landmarks['left_knee'], 12, (0, 0, 255), 3)\n",
    "            cv2.circle(frame, landmarks['right_knee'], 12, (0, 0, 255), 3)\n",
    "        \n",
    "        if 'hips_tight' in issues or 'hips_loose' in issues:\n",
    "            # Highlight hips\n",
    "            cv2.circle(frame, landmarks['left_hip'], 12, (0, 0, 255), 3)\n",
    "            cv2.circle(frame, landmarks['right_hip'], 12, (0, 0, 255), 3)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN APPLICATION\n",
    "# ============================================================================\n",
    "\n",
    "class ExerciseGradingSystem:\n",
    "    \"\"\"Main application class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pose_analyzer = PoseAnalyzer()\n",
    "        self.form_feedback = FormFeedback()\n",
    "        self.voice_coach = VoiceCoach(enabled=Config.VOICE_ENABLED)\n",
    "        self.visualizer = Visualizer()\n",
    "        \n",
    "        print(\"üèãÔ∏è AI Exercise Grading System Started\")\n",
    "        print(\"üìπ Camera initializing...\")\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Main loop\"\"\"\n",
    "        # Initialize webcam\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Error: Could not open webcam\")\n",
    "            return\n",
    "        \n",
    "        print(\"‚úÖ Camera ready!\")\n",
    "        print(\"\\nüìã Instructions:\")\n",
    "        print(\"  ‚Ä¢ Stand in view of camera\")\n",
    "        print(\"  ‚Ä¢ Perform squats\")\n",
    "        print(\"  ‚Ä¢ Press 'q' to quit\")\n",
    "        print(\"  ‚Ä¢ Press 'r' to reset rep count\\n\")\n",
    "        \n",
    "        # Welcome voice\n",
    "        self.voice_coach.speak(\"Welcome! Start your squats when ready.\", priority=True)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Error reading frame\")\n",
    "                break\n",
    "            \n",
    "            # Flip for mirror effect\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # Get pose landmarks\n",
    "            landmarks = self.pose_analyzer.get_landmarks(frame)\n",
    "            \n",
    "            if landmarks:\n",
    "                # Calculate angles\n",
    "                angles = self.pose_analyzer.calculate_body_angles(landmarks)\n",
    "                knee_tracking = self.pose_analyzer.check_knee_tracking(landmarks)\n",
    "                \n",
    "                # Analyze form\n",
    "                feedback_data = self.form_feedback.analyze_squat_form(angles, knee_tracking)\n",
    "                \n",
    "                # Check for rep completion\n",
    "                rep_completed = self.form_feedback.update_rep_count(angles)\n",
    "                if rep_completed:\n",
    "                    if feedback_data['is_good_form']:\n",
    "                        self.voice_coach.speak(\"Good rep!\")\n",
    "                    else:\n",
    "                        self.voice_coach.speak(\"Rep counted, but watch your form\")\n",
    "                \n",
    "                # Voice feedback for major issues\n",
    "                if 'back_bent' in feedback_data['issues']:\n",
    "                    self.voice_coach.speak(\"Keep your chest up\")\n",
    "                elif 'shallow' in feedback_data['issues']:\n",
    "                    self.voice_coach.speak(\"Go deeper\")\n",
    "                elif 'knee_forward' in feedback_data['issues']:\n",
    "                    self.voice_coach.speak(\"Knees back\")\n",
    "                \n",
    "                # Draw skeleton\n",
    "                self.pose_analyzer.mp_draw.draw_landmarks(\n",
    "                    frame, landmarks['raw'],\n",
    "                    self.pose_analyzer.mp_pose.POSE_CONNECTIONS\n",
    "                )\n",
    "                \n",
    "                # Draw angles\n",
    "                self.visualizer.draw_angle(\n",
    "                    frame, landmarks['left_hip'], landmarks['left_knee'], \n",
    "                    landmarks['left_ankle'], angles['left_knee'], (0, 255, 0)\n",
    "                )\n",
    "                \n",
    "                # Highlight problem areas\n",
    "                self.visualizer.highlight_problem_joints(\n",
    "                    frame, landmarks, feedback_data['issues']\n",
    "                )\n",
    "                \n",
    "                # Draw feedback panel\n",
    "                self.visualizer.draw_feedback_panel(\n",
    "                    frame, feedback_data, self.form_feedback.rep_count\n",
    "                )\n",
    "            else:\n",
    "                # No pose detected\n",
    "                cv2.putText(frame, \"No person detected\", (50, 50),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('AI Exercise Grading System', frame)\n",
    "            \n",
    "            # Handle keys\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            elif key == ord('r'):\n",
    "                self.form_feedback.rep_count = 0\n",
    "                self.voice_coach.speak(\"Rep count reset\")\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"\\n‚úÖ Session complete! Total reps: {self.form_feedback.rep_count}\")\n",
    "\n",
    "# ============================================================================\n",
    "# RUN APPLICATION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = ExerciseGradingSystem()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7ffeb-2ada-4a63-88a8-6bc76570bae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
